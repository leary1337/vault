---
создал заметку: 2024-08-07 17:35
tags:
  - golang
  - internal
---
### Описание

Базовое поведение:

![](https://i.imgur.com/ZfNL2VJ.gif)

Когда в коде есть ссылка или указатель:

![](https://i.imgur.com/ykdBXui.gif)

Проблема Dangling pointer (висячий указатель):

![](https://i.imgur.com/3LdHnT6.gif)

- Значение будем получать из некой функции — и не просто значение, а ссылку на него.
- Проинициализировали `x` равный `nil`, потому что мы пока не знаем, что вернет функция `getValue`.
- Зашли в `getValue`, инициализировали `x=4` по адресу `0xc000040742`. Заметьте, что этот адрес находится в следующем стек-фрейме.
- Этот адрес из второго стек-фрейма, который остаётся на месте, хотя стек-пойнтер сдвинулся вверх, передали в адрес `0xc000040842`.
- Дальше идёт функция `println`, которая создаст новый стек-фрейм на предыдущем, и *возникает «dangling pointer» (висячий указатель)*.

Решение проблемы - храним такие объекты не на стеке, а в heap.

Как я могу знать, где Golang выделяет память под переменные — в хип или в стек?

Посмотреть, где у вас выделяются значения — на хипе или на стеке — можно путем команды: `go build -gcflags=«-m»`. Причём, чем больше букв `m`, тем более подробно будет выведена информация.

Тем не менее разработчики языка гарантируют, что Golang всегда будет стараться выделить значение переменных на стеке, кроме некоторых исключительных ситуаций.
#### Escape analysis

**Escape Analysis** — это механизм, который решает, будет ли храниться значение на стеке или на хипе.

Место вызова:

```go
// go1.22.5/src/cmd/compile/internal/gc/main.go

func Main(archInit func(*ssagen.ArchInfo)) {
	// ...
	
	// Escape analysis.  
	// Required for moving heap allocations onto stack,  
	// which in turn is required by the closure implementation,  
	// which stores the addresses of stack variables into the closure.  
	// If the closure does not escape, it needs to be on the stack  
	// or else the stack copier will not update it.  
	// Large values are also moved off stack in escape analysis;  
	// because large values may contain pointers, it must happen early.
	escape.Funcs(typecheck.Target.Funcs)
	
	// ...
}
```

```go
// go1.22.5/src/cmd/compile/internal/escape/excape.go

func Funcs(all []*ir.Func) {
	ir.VisitFuncsBottomUp(all, Batch)
}
```

Здесь интересен callback `Batch`. Разберём примерно его алгоритм. 

В начале строится направленный граф весов. Что такое граф весов? Представим, что у нас есть структура `T struct с полем Value`, и есть некая функция `tryToEscape`, у которой 4 переменные. Причем `l3` отдается по ссылке. Тогда по алгоритму будет построен граф:

![](https://i.imgur.com/3KAtMJ2.png)

Появилась переменная `r1` — это так называемая псевдопеременная. В этом графе нодой являются сами переменные, ребра — это присваивание, а веса `(0, -1, 1, -1)` — это типы этих присваиваний:

- `0` проставляется в случае, если это обычное присваивание, как в случае `l1 = a`;
    
- `-1` проставляется, если мы берем ссылку от переменной;
    
- `1` — если идет разыменование.

Сам алгоритм, который решает должно ли значение уходить в heap или нет, находится в файле `solve.go` в пакете `escape`:

```go
// go1.22.5/src/cmd/compile/internal/escape/excape.go

func Batch(fns []*ir.Func, recursive bool) {
	// 1. Построение графа ...
	
	// 2. Проверка на размер переменных
	for _, loc := range b.allLocs {
		if why := HeapAllocReason(loc.n); why != "" {
			b.flow(b.heapHole().addr(loc.n, why), loc)
		}
	}

	b.walkAll() // 3. Обход графа
	b.finish(fns) // 4. Завершение алгоритма и разметка переменных
}
```

Если разбивать это кусок кода на 3 части, то это будет выглядеть так:

1. Вначале строится граф

2. Потом происходит проверка на размер переменных. Дело в том, что у каждого типа переменной есть свой лимит на размер.

3. Наконец, обход графа (`walkAll`) и выдвижение решения того, уходит ли в хип переменная или нет.

Примерно так работает эскейп анализ. Теперь, понимая, как примерно устроен escape analysis в golang, мы можем посмотреть на устройство аллокатора heap.
#### Heap allocator и проблема фрагментации

Аллокатор хип основан на **TCMalloc (Thread-Caching Allocator)**. Главная идея заключается в «слоистом» представлении памяти и в отдельных блоках памяти для каждого треда, в которые он обращается без lock.

Рассмотрим это более детально, но уже в языке Go. Представим, что у нас есть какое-то приложение и где-то есть виртуальная память для него. Мы говорим: «Дай нам, пожалуйста, кусочек памяти», и ОС его дает. Все замечательно. Но что произойдет, если мы внезапно захотим много кусочков памяти? В этом случае у нас произойдёт падение производительности.

Как с этим борются в Golang? Очень просто. Они просят не маленький кусочек памяти, а сразу огромный кусок, а потом решают, что с ним делать. Этот кусок памяти в аллокаторе называется ареной. Когда арена заканчивается, запрашивается ещё арена, и ещё арена, и ещё арена.

![](https://i.imgur.com/cZi5Aq8.png)

Размер этой арены рассчитывается по формуле.

Чтобы не утруждать вас чтением этой формулы, есть табличка с размерами арен для каждой из платформ:
![](https://i.imgur.com/NBKYUns.png)

Здесь указано, на какой платформе какой размер арены. Например, если у вас лаптоп на Linux 64 bit, то у вас арена будет весить 64Mb.

Важно подчеркнуть, что арена — это не просто кусок памяти. Как только мы получаем арену, например, в 64мб, то она сразу будет поделена на 8kb странички.

Арены и странички (arena и pages) не имеют никакой метаинформации о них. Это просто вшитые константы, которые вычисляются на момент компиляции. Всем этим свором (аренами и страничками) управляет «мама»-структура — heap arena или mheap в самом аллокаторе.

![](https://i.imgur.com/baWywqV.png)
##### Фрагментация

![](https://i.imgur.com/wxuIzFd.gif)

Теперь представим, что есть некий фрагмент арены.
- Пусть каждый маленький синий блок будет 1b. Мы говорим: «Хотим 4 байта!» — «Пожалуйста!»
- «Хотим 1 байт!» — «Пожалуйста!»
- «Много байт!» — «Пожалуйста!»
- После того как мы поигрались, мы говорим, что не хотим вот эти и эти два байта — «Замечательно, я их удаляю!».

И мы радуемся, что у нас есть теперь 4 свободных байта, куда можно запихать переменную размером в 4b… А вот фигушки! Потому что эта пара по 2b находятся в разных местах. Мы получили так называемую внешнюю фрагментацию. 

Как с ней борются в Golang? Разработчики начали думать. Так, есть программисты и есть использование разных размеров переменных. Давайте выясним, какого размера переменные часто используют программисты и создадим для этих размеров пулы.
#### Pool объектов

У нас есть арена. На этой арене выделим пулы для разных размеров переменных. То есть, если есть переменные в 16b, сразу выделим пул в 16b. Если есть переменная в 32b, сразу выделим пул в 32b, и т.д. Такой пул называется в аллокаторе mspan.

**mspan** — это минимальный юнит в аллокаторе, который уже имеет метаинформацию о переменных. У mspan есть поле spanClass, которое хранит тип класса для данного пула. Класс определяет для какого размера создан этот пул. Mspan 1-го класса означает, что он создан для переменных 8b, а если 3-го класса, то для переменных 24b.

Вы можете сами посмотреть какие есть классы так как разработчиками сгенерирована табличка со всеми этим классами и информацией по ним. Она находится в пакете runtime/sizeclasses.go

![](https://i.imgur.com/UHvOfsG.png)

Третий столбец говорит о том, сколько страниц тратится на данный пул. Видно, что для mspan класса 1 тратится 1 страница, потому что в этом третьем столбце написано 8192 байта. В Golang всего 67 классов. Для 67-го класса тратится 4 страницы.

Четвертый столбец (objects) говорит, сколько, максимум, объектов помещается в этот пул. Посчитать это очень легко: возьмем первую строчку из таблицы, возьмем размер пула 8192 поделим на размер объекта в этом пуле 8 и получим количество этих объектов 1024.

Давайте теперь обратим внимание на последние два столбца: tail waste и max waste.

О чем говорит tail waste? Он говорит о том, что, используя пул с размером блока в 48 байт, к примеру, мы всегда гарантированно будем терять 32b потому, что пул состоит из одной страницы размером в 8192b. Пытаемся поделить её на 48 и понимаем, что никак на цело не делится. Получается, что у нас всегда будет пустовать 32b(как остаток от деления).

О чем говорит max waste? Он говорит о том, что в худшем случае для данного класса пула мы будем терять 31% памяти. Это так называемая внутренняя фрагментация.

Худший случай для класса 5 (пул 48b) — 33b, потому что это минимальный размер переменной, которое можно туда поместить, и мы всегда будем терять 15b. Они всегда будут пустовать в этом блоке. Об это нам и говорят разработчики.

Естественно, эти пулы заканчиваются, и когда это происходит, создаётся ещё один пул (ещё один mspan). Все эти mspan соединены друг с другом в двусторонний связанный список.

![](https://i.imgur.com/3Wnzidr.png)

Поля next и prev указывают на следующее и предыдущее mspan.

Также из интересного — поле startAddr, которое говорит, где именно на арене начинается данный пул.

![](https://i.imgur.com/qgr53kM.png)

Кроме этого здесь есть:

1) Поле `npages`. Оно показывает из какого количества страниц состоит данный пул.

2) Поле `freeindex`. Оно нужно для того, чтобы моментально находить свободный блок в данном пуле.

3) Поле `nelems`. Оно говорит о том, сколько всего элементов в данном пуле

4) Также есть интересное поле `allocBits`. Оно показывает свободные ячейки в данном пуле. Нужно для поиска и для garbage collector.

Если `mspan` связывается в двусторонний список, то должна быть какая-то структура, которая управляет этим списком. За это отвечает структура `mcentral`. Один `mcentral` закрепляется за одним классом. Соответственно, всего будет 67 `mcentral`, так как всего 67 классов.
![](https://i.imgur.com/FcrTXph.png)

Отсюда, у `mcentral` есть поле `spanclass`, которое говорит, что данный `mcentral` принадлежит такому-то классу, и в нем содержаться `mspan` такого-то класса. Также у `mcentral` есть два списка:

· `nonempty`. В нем содержится список `mspan`, в которых уже есть какая-то информация.

· `еmpty`, в котором содержатся пустые `mspan`

С течением `runtime` эти списки друг с другом тусуются. Если где-то освобождается информация, то `mspan` переходит в `empty`. Если где-то информация занимает место, то `mspan` переходит в `nonempty`.
#### Go Concurrency model. Работа с несколькими тредами

Что, если у нас несколько тредов и один блок памяти? Если треды начнут запрашивать память, мы получим **race condition**. Как с этим можно бороться?

Мы знаем , что в ситуации c race condition нас точно спасет lock. Если первый тред запрашивает память, то мы ставим lock, выделяем и записываем память. Если второй, то пусть ждет, пока первый доделает свои дела.

![](https://i.imgur.com/F3aeOy8.png)

Всё просто, но мы получаем падение производительности. Пока кто-то чего-то дождётся, только потеряем время.

Разработчики Golang борются с этим очень просто — вводом кэша.

![](https://i.imgur.com/MUOM6mz.png)

На каждый тред есть сразу отдельный блок памяти с выделенным для него `mspan`. Каждый тред работает со своим определённым кешем. За этот кеш отвечает структура `mcache`.

![](https://i.imgur.com/9dW9fQS.png)

Из интересного - `mcache` имеет поле `alloc`. Это массив, состоящий всего лишь из 2 элементов с индексом 0 и 1. По индексу 0 лежит двусвязный список `mspan`, который содержит в себе переменные, указатели на другие указатели. По индексу 1 лежат переменные, которые не содержат указатели. Это некая оптимизация для garbage collector, чтобы он лишний раз не делал traverse.
#### 100% выделение на хипе

Есть три неизменяемых правила выделения памяти от версии к версии Golang. У вас 100% выделится значение на хипе, если:

1. Возврат результата происходит по ссылке;
    
2. Значение передается в аргумент типа interface{} — аргумент fmt.Println;
    
3. Размер значения переменной превышает лимиты стека.
### Краткое содержание

В Golang управление памятью осуществляется с помощью **escape analysis**, который определяет, следует ли хранить переменные на стеке или в хипе. Этот процесс включает построение графа присваиваний и анализ размера переменных. Аллокатор памяти в Golang основан на **TCMalloc**, который управляет памятью через *арены, разбитые на страницы и mspan-пулы для разных размеров объектов*. Для избежания фрагментации памяти *используются пулы фиксированных размеров*. С многопоточностью Golang справляется, используя кеши (**mcache**) для каждого потока, что позволяет избегать проблем с блокировками и race condition. ^sum-allocation
