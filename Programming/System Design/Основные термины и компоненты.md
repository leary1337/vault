---
создал заметку: 2024-07-31
tags:
  - system-design
  - terminology
---
### Описание

#### Архитектуры информационных систем

**Файл-сервер (устарела):**
Файл-сервер только извлекает данные из файла или базы данных и передает их клиенту для дальнейшей обработки

- небезопасно (отдавать клиенту все данные, что бы он с ними что-то делал)
- придется нагружать клиента логикой (не все клиенты имеют мощные ЭВМ)

Используется, когда мы просто загружаем какие-то файлы (Google Drive, DropBox)

Но есть Google Drive, где мы сами загружаем файл, за нас сервер не производит никакой обработки (не фильтрует, не ищет)

![](https://i.imgur.com/O68mDRc.png)

**Клиент-сервер (популярно):**
Клиент-сервер извлекает данные из файла или база данных, обрабатывает и затем передает результат клиенту

- не отдаем лишнюю информацию
- не грузим клиента логикой
- безопасно (клиент не сможет повредить наши данные или что-то сломать)

![](https://i.imgur.com/i9SPH4n.png)

**Peer to Peer (P2P):**
Все узлы выполняют одинаковые функции - нет централизованного сервера

Нет клиента и сервера - просто одноранговые узлы (каждый узел в своем понимании является и клиентом и сервером)

- blockchain
- torrent

![](https://i.imgur.com/fYdTj5B.png)
#### Основные критерии ИС

**Надежность:**

Система должна продолжать работать корректно даже при неблагоприятных обстоятельствах

Метрики надежности и доступности:

метрика availability меряется в количестве 9-ок

| Availability Level        |          | Average Yearly Downtime |
| ------------------------- | -------- | ----------------------- |
| Conventional Server       | 99%      | 87 hours, 40 minutes    |
| Public Cloud Service      | 99.5%    | 43 hours, 50 minutes    |
|                           | 99.9%    | 8 hours, 46 minutes     |
| High-Availability Cluster | 99.95%   | 4 hours, 23 minutes     |
| Virtual Fault Tolerance   | 99.995%  | 26 minutes, 18 seconds  |
| Continuous Availability   | 99.999%  | 5 minutes, 16 seconds   |
| The Stratus Zone          | 99.9999% | 31.6 seconds            |
6 девяток => в год я недоступен 31.6 секунды

Показатель на сколько мы доступны

Как правило 4-5 девятки - норм (юзер не заметит)

**SLA/SLO/SLI**

- SLA (Service Level Agreement) - соглашение, которое вы заключаете со своими клиентами
	- Что произойдет если SLO будет нарушено (какие я последствия предоставлю пользователям как бизнес) (вернет ли бизнес деньги, акции, скидки)
- SLO (Service Level Objectives) - цели, которые команда должна решить, чтобы выполнить соглашение
	- Есть цель на команду - держать 4 девятки => доступность должна быть 99.99%
- SLI (Service Level Indicators) - показатели системы
	- Есть метрика Uptime или Downtime.

Пример метрики Google Drive:
![](https://i.imgur.com/j9OBcbJ.png)

Что гугл дает, если SLO будет нарушено:
![](https://i.imgur.com/6M0MU1o.png)

**Масштабируемость**

Должны быть предусмотрены разумные способы решения возникающих при росте системы проблем

**Вертикальное:**
Стоимость увеличения ресурсов растет не линейно, относительно их увеличения мощности (возможен downtime). Также невозможно бесконечно масштабироваться

Покупаю более мощное железо для своего ПК

downtime возможен, так как не все сервисы могут поддерживать замену комплектующих на горячую (заменить плашку оперативы, проц другой воткнуть)

![](https://i.imgur.com/05VizGm.png)

**Горизонтальное:**
Чаще всего масштабирование происходит без каких-либо проблем

Вместо одного сервера ставим три (докупаем)

![](https://i.imgur.com/4Cqajfv.png)

**Stateless and Statefull**

Сервисы делятся на два типа:
- Stateless:
	- не хранят никакого состояния
	- масштабируются просто
- Statefull:
	- хранят какое-то состояние
	- масштабировать сложно (будем ли мы мигрировать данные с одного сервиса на другой?)

**Производительность:**

Есть основополагающие метрики - Latency и Response Time

Latency - задержка. Клиент отправляет запрос на сервер и вот пока сервер не начнет обрабатывать этот запрос - это время это и есть задержка.

![](https://i.imgur.com/TjmeqQo.png)


Response time - время ответа. t1 + t2 + ... + t7 = response time (включает в себя latency)

![](https://i.imgur.com/8A06AST.png)

**Low-latency приложения**
Такие приложения надо с самого начала писать с оптимизациями, с прямой ориентацией на low-latency. Подход, когда пишут сначала просто работающее приложение, а потом оптимизируют его, здесь не работает

**Метрика throughput**

Пропускная способность

Например:
за 1 сек клиент отправляет 200 запросов на сервер
сервер успевает 120 запросов переадресовать БД
БД успевает обработать 100 запросов 
А сервер успевает обратно отправить 95 запросов

То есть клиент в итоговой сумме за 1 секунду получает 95 ответов на свои 200 запросов

![](https://i.imgur.com/Gs1g2bx.png)

![](https://i.imgur.com/Av2WJz7.png)

**High-throughput приложения**
Приложения, заточенные под максимально возможную пропускную способность - latency в этом случае часто пренебрегают.

**"Типичные" приложения (что чаще всего нужно)**
Нужен максимально возможный throughput по какому-то определенному latency


**Удобство сопровождения**
Необходимо обеспечить возможность эффективной работы с системой множеству различных людей.

За счет чего достигается удобство:
- observability (мониторинг)
- Улучшение процессов (доставка кода, тесты, деплой)
- Дополнительный инструментарий (уменьшение ручного воздействия)

**Безопасность**

Варианты приложения:
- Передача данных в открытом виде
- Транспортное шифрование
- Сквозное шифрование
#### Основные свойства ИС

Что из этого HighLoad?
20 RPS или 20 000 RPS
Ответ: и то и то. Можно на 20 рпс жестко грузить цпу и тп, а на 20000 тупо редиректить трафик

**Data-intensive**

- нужно сохранять большие данные
- нужно запоминать результаты ресурсоемких операций
- нужно предоставлять пользователям возможность искать или фильтровать данные

Еще называют I/O Bound приложение

**Compute-intensive**

CPU Bound приложение

- нужно делать много вычислительных операций
- нужно "перемалывать" большие объемы данных


**Read / Write Ratio**

При проектировании системы важно понимать, в системе будут больше читать или писать.
Соц сети - редко пишут посты, часто читают
Системы логов - редко читаем, чаще пишем
#### Архитектура бэкенда

![](https://i.imgur.com/Zli2Ocz.png)

**Микросервисы:**
- Микросервисы необязательно про размер, как правило это про зону ответственности
	- сервис user отвечает за взаимодействие с пользователями
	- сервис credit отвечает за выдачу кредитов в банке
- Самодостаточный, идеальны для горизонтального масштабирования
- Разные технологии для разных задач
- Распределенная кодовая база

Плюсы:
- Независимые релизы и разработка
- Независимая масштабируемость
- Независимая деградация (упар сервис юзеров, не факт что упал сервис кредитов)
- Возможность пробовать новые технологии

Минусы:
- Зоопарк технологий
- Сетевой вызов отвалится вероятнее, чем внутренний
- Распределенность и транзакционность
- Удаленные вызовы дороже локального исполнения
- Понимание всего контекста запроса
- Сложность тестирования всей системы

Монолиты для стартапов и low-latency
Микросервисы для всего остального
#### Балансировка нагрузки

**Клиентская балансировка:**

Работает быстрее, но проблемы с эксплуатацией (инстанс упал, нужно донести клиенту).
Клиент имеет данные о каждом инстансе и сам распределяет нагрузку.

![](https://i.imgur.com/bQXkbsV.png)

**Серверная балансировка:**

На LB приходит трафик и он его распределяет

![](https://i.imgur.com/qlyj5M0.png)

Как распределяет:

Random:

Выбирает инстанс рандомно (будет неэффективное распределение)

![](https://i.imgur.com/Reb6CWS.png)

Round Robin:
80-90% задач закрывает

Распределение задач по кругу

![](https://i.imgur.com/ksnP0bG.png)

Weighted RR:

Взвешенный Round Robin
Направляем на тот инстанс, который может больше трафика перемалывать, у которого больше ресурсов (программист Вася быстрее других закрывает задачки)

Нужно, когда сетевые узлы имеют разные технические характеристики (ситуация редкая)

![](https://i.imgur.com/kr0b7O7.png)

Sticky Sessions:

хеш-таблица по сути
Хешируем ключ и от остатка от деления попадаем на нужный инстанс для конкретного юзера

![](https://i.imgur.com/hU0hy2K.png)

Least Connections / RT (response time) / Bandwidth:

LB смотрит где наименьшее открытое количество соединений туда и пойду, а где меньше респонс тайм и тд

(редко юзается)

![](https://i.imgur.com/3or89b7.png)

Power of two choices:

Случайным образом выбираем два бэкенда из списка - из этих двух выбираем лучший по целевой метрики (least connections / sessions / ...)
Тоже редко

nginx:

Популярный балансировщик нагрузки

есть location указали там url и upstream
в upstream балансируем (для первого сервера будет алго Weighted RR)

![](https://i.imgur.com/LuojZMW.png)


L4 / L7 балансировка:

L4 - работает на сетевом + транспортном уровне
L7 - на прикладном

![](https://i.imgur.com/byABhSo.png)

DNS балансировка:

![](https://i.imgur.com/Nv6EuDp.png)


geoDNS балансировка:

Дата центры есть в индии и сша
хочется чтоб юзеры сша шли в дц сша, а индийские парни в индийский дц
будет меньше latency

![](https://i.imgur.com/EBrKy4j.png)
#### Проксирование

Оно нужно для:
- Взлом / защита
- Кэширование данных
- Ограничения трафика
- Обход ограничений доступа
- Анонимность пользователей
- Сжатие и модификация данных

![](https://i.imgur.com/ZCIMzEg.png)

Forward Proxy:

Клиент (приложение) знает, что он идет через проксю (левый сервис шарит за прокси)

![](https://i.imgur.com/dOpAnJm.png)

Reverse Proxy:

Клиент (приложение) не знает, что там стоит прокся

![](https://i.imgur.com/d07hFJQ.png)
#### Кэширование

- Сокращение response time сервисов
- Снижение лишней нагрузки на сторонние сервисы
- Переиспользование ранее полученных или вычисленных данных
- Стабилизация работы при кратковременных отказах систем

**Основные термины:**

- **cache miss** - промах кэша, запрошенный ключ не был найден в кэше
- **cache hit** - попадание в кэш, запрошенный ключ найден в кэше
- **hit ratio** - процент попаданий запросов в кэш, характеризует эффективность кэширования
- **Горячий ключ** - ключ, на который приходится большая часть запросов
- **Прогрев кэша** - процесс наполнения кэша данными
- **Инвалидация** - удаление кэшированных данных

**Какие данные кэшировать:**

- **Меняются часто (секунды)** - кэшировать чаще всего бессмысленно, но иногда может пригодиться
- **Меняются нечасто (минуты и часы)** - чаще всего здесь задаемся вопросом - "стоит ли мне кэшировать" (смотреть hit ratio)
- **Меняются редко (дни, недели, месяца)** - в данном случае можно спокойно кэшировать эти данные

**Кэширование ошибок:**
Кэшируем ошибки и тогда последующие запросы не будут обращаться к источнику информации, а также не будет *cache miss attack (можно класть БД например)*

**По хорошему, нужно уметь держать нагрузку без кэша**
Задача кэша - ускорить ответ, а не держать нагрузку

**Полезность кэша:**

Эффективность:
AverageTime = DBAccessTime * CacheMissRate + CacheAccessTime

Пусть:
- DBAccessTime = 100ms
- CacheAccessTime = 20ms

Тогда при CacheMissRate > 0.8 - кэш вреден!
Потому что доступ к данным будет > 100ms (юзай просто БД без кэша)

время можно брать как по latency, так и по RT

**Виды кэширования:**

Внутреннее кэширование - кэш внутри сервиса => сервис является statefull

Плюсы:
- Высокая скорость
- Отсутствие сетевых запросов
- Нет расходов на Marshaling/Unmarshaling данных

Минусы:
- Горизонтальное масштабирование
- Прогрев кэша после падения сервиса

![](https://i.imgur.com/WExPRL3.png)

Внешнее кэширование - сервис не хранит, а ходит в другой storage

Плюсы:
- Хранение большого объема данных
- Простое горизонтальное масштабирование
- После падения сервиса данные кэша не теряются
- Простой прогрев кэша и простая логика инвалидации

Минусы:
- Скорость работы

![](https://i.imgur.com/l2oV3EJ.png)

**Способы взаимодействия с кэшем**

Cache Aside (кэширование на стороне)

В этой стратегии, приложение координирует запросы в кэш и БД, и само решает куда и в какой момент нужно обращаться

![](https://i.imgur.com/4LvGfdn.png)

![](https://i.imgur.com/ouBvOGs.png)

Cache Through (сквозное кэширование)

В рамках этой стратегии все запросы от приложения проходят через кэш
Приложение знает только о кэше

упал кэш - упало приложение

![](https://i.imgur.com/r3Wr0zO.png)


![](https://i.imgur.com/oMw7vJj.png)

Cache Ahead (опережающее кэширование)

Запросы на чтение всегда идут только в кэш, никогда не попадая в БД напрямую

![](https://i.imgur.com/URnCSnM.png)

Выбор кэша:
- Важно учитывать актуализацию данных
- Стоит балансировать между характером нагрузки (read / write)
- Отказоустойчивость (не забывать)

**Алгоритмы вытеснения данных**

Кэш не безграничен

Пришел user_5 но места в кэше нет, нужно кого-то вытеснить

![](https://i.imgur.com/cdluQtf.png)

**Random (редко):**

![](https://i.imgur.com/yUqq8Fs.png)

**FIFO:**

![](https://i.imgur.com/hVjdbcv.png)

**LIFO:**

![](https://i.imgur.com/qB9xGbv.png)

**LRU:**

Не использованный дольше всех вылетает из кэша

![](https://i.imgur.com/D7V9hRM.png)

**MRU:**

Последний использованный вылетает из кэша (специфичный кейс, бережем старье)

![](https://i.imgur.com/jDO578I.png)

**LFU:**

Реже всего использованный вылетает из кэша

![](https://i.imgur.com/7uOnJJR.png)

**Алгоритм Белади (OPT):**

Теоретический алгоритм (нереализуем)

![](https://i.imgur.com/ycnsguz.png)

**Second Chance:**

Очередь FIFO, только с битом использования. Для вытеснения делаем проход по очереди, если бит использования равен 0, то вытесняем, если бит равен 1, то устанавливаем в 0 и идем дальше, если не нашли ни одного бита равным 0 - делаем проход заново

![](https://i.imgur.com/E8aKqes.png)

При обращении выставляем бит присутствия, а при вытеснении удаляем из начала очереди, если бит равен 0, а если равен 1, то меняем бит на 0, затем переносим элемент в конец очереди и идем к следующему

![](https://i.imgur.com/HWGixLO.png)

**Clock:**

Тот же Second Chance, только не нужно двигать элемент из начала в конец очереди, если бит равен 1

![](https://i.imgur.com/KNtEv45.png)

**2Q:**

Элементы запрошенные из 1FIFO никуда не двигаются. Вытесненные из 1FIFO - перемещаются в 2FIFO

Элементы запрошенные из 2FIFO - уходят в LRU. Вытесненные из 2FIFO удаляются

![](https://i.imgur.com/AB1gfCn.png)

**SLRU:**

Сперва кладем в первую коробочку, при повторном запросе перекладываем во вторую, при еще одному повторном из второй - в третью

LRU + LFU = SLRU

![](https://i.imgur.com/Nm7Uc0j.png)

**TLRU (Time aware LRU):**

Абсолютно точно такой же алгоритм, только к данным добавляется их время жизни в кэше (TTL), по которому они автоматически удаляются из кэша

**LRU-k:**

Удаляет страницу, K-й последний доступ к которой находится дальше всего в прошлом. Например, LRU-1 - это просто LRU, тогда как LRU-2 удаляет страницы в соответствии со временем их предпоследнего доступа

#### API

CRUD - Create Read Update Delete операции
Акроним обозначающий четыре базовые функции

**REST:**

![](https://i.imgur.com/CmyQMzE.png)

- Глагол - метод запроса (GET, POST, DELETE, PUT)
- Существительное - URI запроса
- Дополнительная информация - хедеры запроса
- Содержимое - тело запроса и ответа в JSON
- Результат - код ответа

**SOAP:**

Устарело, почти нигде не используется

![](https://i.imgur.com/ym69FA0.png)

![](https://i.imgur.com/rvlfPnd.png)


**RPC:**

Класс технологий, позволяющих программам вызывать функции или процедуры в другом адресном пространстве

**gRPC:**

![](https://i.imgur.com/uCt0xu1.png)

![](https://i.imgur.com/exOZNOv.png)

![](https://i.imgur.com/FhEn8YT.png)

**Under / Over fetching:**

Отдаю лишние данные, которые не нужны - Over fetching
Не додал данных в апи нужно запросить еще - Under fetching

**GraphQL:**

Сервис как БД

**![](https://i.imgur.com/mowysoL.png)
![](https://i.imgur.com/xhHImX7.png)

![](https://i.imgur.com/VTUztwh.png)
![](https://i.imgur.com/UXhnyQO.png)

![](https://i.imgur.com/oHGiA9d.png)
![](https://i.imgur.com/NmE4scT.png)

- SOAP уже умер
- REST для клиентского взаимодействия
- gRPC для внутренного взаимодействия
- GraphQL для кастомизации запросов
#### Observability

Prometheus, grafana

Jaeger, Zipkin

Elasticsearch + logstash + kibana
graylog

parco, pyroscope

sentry

Основные метрики:
- RPS, TPS, QPS
- Response time
- Errors rate
- Traffic, CPU, RAM, HDD/SDD
- Uptime / Downtime
- Размеры очередей
- Количество процессов / потоков
### Краткое содержание
